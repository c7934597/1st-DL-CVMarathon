{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 38s 0us/step\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100)`\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 39s 775us/step - loss: 1.3536 - acc: 0.5227\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 38s 754us/step - loss: 0.9946 - acc: 0.6517\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 40s 803us/step - loss: 0.8275 - acc: 0.7110\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 38s 752us/step - loss: 0.7211 - acc: 0.7485\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.6298 - acc: 0.7808\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 36s 730us/step - loss: 0.5481 - acc: 0.8089\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 40s 804us/step - loss: 0.4823 - acc: 0.8329\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 38s 764us/step - loss: 0.4176 - acc: 0.8536\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 42s 843us/step - loss: 0.3650 - acc: 0.8724\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 45s 902us/step - loss: 0.3094 - acc: 0.8921\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.2658 - acc: 0.9074\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.2292 - acc: 0.9208\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 0.1937 - acc: 0.9325\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.1643 - acc: 0.9430\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 54s 1ms/step - loss: 0.1499 - acc: 0.9473\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.1366 - acc: 0.9513\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1114 - acc: 0.9608\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.1070 - acc: 0.9631\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1073 - acc: 0.9627\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0996 - acc: 0.9647\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 42s 843us/step - loss: 0.0982 - acc: 0.9657\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.0805 - acc: 0.9727\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.0770 - acc: 0.9730\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.0776 - acc: 0.9714\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 37s 735us/step - loss: 0.0683 - acc: 0.9760\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.0671 - acc: 0.9760\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.0694 - acc: 0.9759\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 37s 737us/step - loss: 0.0755 - acc: 0.9735\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 36s 728us/step - loss: 0.0596 - acc: 0.9800\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 37s 735us/step - loss: 0.0672 - acc: 0.9769\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 45s 894us/step - loss: 0.0718 - acc: 0.9745\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.0599 - acc: 0.9791\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0500 - acc: 0.9827\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0581 - acc: 0.9799\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.0529 - acc: 0.9813\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.0563 - acc: 0.9806\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0600 - acc: 0.9795\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 52s 1ms/step - loss: 0.0484 - acc: 0.9835\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 38s 757us/step - loss: 0.0443 - acc: 0.9851\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 42s 831us/step - loss: 0.0569 - acc: 0.9801\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 44s 886us/step - loss: 0.0476 - acc: 0.9840\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 44s 877us/step - loss: 0.0453 - acc: 0.9847\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 44s 885us/step - loss: 0.0412 - acc: 0.9856\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 46s 914us/step - loss: 0.0546 - acc: 0.9811\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 44s 885us/step - loss: 0.0538 - acc: 0.9817\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0390 - acc: 0.9866\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 46s 915us/step - loss: 0.0395 - acc: 0.9861\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 46s 920us/step - loss: 0.0414 - acc: 0.9853\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.0349 - acc: 0.9881\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 46s 919us/step - loss: 0.0482 - acc: 0.9829\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 44s 880us/step - loss: 0.0473 - acc: 0.9834\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 43s 856us/step - loss: 0.0380 - acc: 0.9867\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 42s 847us/step - loss: 0.0428 - acc: 0.9851\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 43s 854us/step - loss: 0.0351 - acc: 0.9882\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 43s 852us/step - loss: 0.0428 - acc: 0.9852\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 42s 844us/step - loss: 0.0451 - acc: 0.9853\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 43s 852us/step - loss: 0.0301 - acc: 0.9895\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 47s 933us/step - loss: 0.0374 - acc: 0.98751s - loss: 0.0364\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 42s 836us/step - loss: 0.0402 - acc: 0.9861\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.0362 - acc: 0.9876\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 36s 721us/step - loss: 0.0292 - acc: 0.9902\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 36s 719us/step - loss: 0.0407 - acc: 0.9858\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 37s 747us/step - loss: 0.0323 - acc: 0.9889\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 0.0376 - acc: 0.9876\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 41s 820us/step - loss: 0.0356 - acc: 0.9883\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 41s 810us/step - loss: 0.0282 - acc: 0.9901\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 42s 830us/step - loss: 0.0326 - acc: 0.9890\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 41s 812us/step - loss: 0.0338 - acc: 0.9890\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 44s 873us/step - loss: 0.0387 - acc: 0.9871\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 47s 944us/step - loss: 0.0315 - acc: 0.9895\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 45s 895us/step - loss: 0.0277 - acc: 0.9904\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 45s 894us/step - loss: 0.0383 - acc: 0.9873\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 43s 853us/step - loss: 0.0289 - acc: 0.9900\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 43s 858us/step - loss: 0.0264 - acc: 0.9911\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 43s 860us/step - loss: 0.0284 - acc: 0.9899\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 45s 891us/step - loss: 0.0357 - acc: 0.9882\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 45s 907us/step - loss: 0.0291 - acc: 0.9904\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 42s 847us/step - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 46s 926us/step - loss: 0.0266 - acc: 0.9908\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 43s 859us/step - loss: 0.0305 - acc: 0.9901\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0366 - acc: 0.9877\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 44s 871us/step - loss: 0.0270 - acc: 0.9908\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 45s 906us/step - loss: 0.0268 - acc: 0.9910\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 41s 817us/step - loss: 0.0249 - acc: 0.9926\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 36s 728us/step - loss: 0.0240 - acc: 0.9923\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 34s 688us/step - loss: 0.0266 - acc: 0.9906\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 35s 691us/step - loss: 0.0281 - acc: 0.9903\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 35s 698us/step - loss: 0.0266 - acc: 0.9913\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 38s 751us/step - loss: 0.0241 - acc: 0.9919\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 38s 759us/step - loss: 0.0289 - acc: 0.9905\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 37s 748us/step - loss: 0.0309 - acc: 0.9897\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.0322 - acc: 0.9894\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 40s 792us/step - loss: 0.0243 - acc: 0.9921\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 43s 852us/step - loss: 0.0258 - acc: 0.9914\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 41s 811us/step - loss: 0.0222 - acc: 0.9929\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 44s 874us/step - loss: 0.0210 - acc: 0.9934\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 38s 759us/step - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 37s 746us/step - loss: 0.0247 - acc: 0.9919\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 38s 766us/step - loss: 0.0273 - acc: 0.9910\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.0242 - acc: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28abfa88>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,input_shape=(32,32,3),activation='relu'))\n",
    "#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(output_dim=100,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(output_dim=10,activation='softmax'))\n",
    "\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5878946e-17, 1.4645323e-20, 1.4070922e-09, 1.0000000e+00,\n",
       "        2.7131605e-10, 2.2072651e-18, 3.9234980e-11, 5.2095061e-17,\n",
       "        1.1272905e-13, 3.1033892e-25]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
